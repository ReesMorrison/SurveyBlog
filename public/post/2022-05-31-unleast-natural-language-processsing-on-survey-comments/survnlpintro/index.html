<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">

  
  <meta name="author" content="Rees Morrison">

  
  
  <meta name="description" content="Law firms and law departments periodically conduct surveys of their members or clients to learn about a topic, e.g., engagement, work-from-home policies, client satisfaction, or use of AI software. Questions on the survey may invite respondents to write as much as they want for an answer. For example, â€œHow have you encountered and dealt with supply-chain obstructions?â€ I will call them â€œtext questions.â€
The old-fashioned way to identify and classify ideas from free-text responses to text questions has been to read and code them by hand.">
  

  
  <link rel="icon" href="https://surveyjds.onrender.com/favicon.ico">

  
  
  <meta name="keywords" content=" hugo  latex  theme ">
  

  
  

  
  <meta property="og:title" content="Unleash Natural Language Processsing on Survey Comments" />
<meta property="og:description" content="Law firms and law departments periodically conduct surveys of their members or clients to learn about a topic, e.g., engagement, work-from-home policies, client satisfaction, or use of AI software. Questions on the survey may invite respondents to write as much as they want for an answer. For example, â€œHow have you encountered and dealt with supply-chain obstructions?â€ I will call them â€œtext questions.â€
The old-fashioned way to identify and classify ideas from free-text responses to text questions has been to read and code them by hand." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://surveyjds.onrender.com/post/2022-05-31-unleast-natural-language-processsing-on-survey-comments/survnlpintro/" />
<meta property="article:published_time" content="2022-05-31T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-05-31T00:00:00+00:00" />


  
  <link rel="canonical" href="https://surveyjds.onrender.com/post/2022-05-31-unleast-natural-language-processsing-on-survey-comments/survnlpintro/">

  
  
  <meta itemprop="name" content="Unleash Natural Language Processsing on Survey Comments">
<meta itemprop="description" content="Law firms and law departments periodically conduct surveys of their members or clients to learn about a topic, e.g., engagement, work-from-home policies, client satisfaction, or use of AI software. Questions on the survey may invite respondents to write as much as they want for an answer. For example, â€œHow have you encountered and dealt with supply-chain obstructions?â€ I will call them â€œtext questions.â€
The old-fashioned way to identify and classify ideas from free-text responses to text questions has been to read and code them by hand.">
<meta itemprop="datePublished" content="2022-05-31T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-05-31T00:00:00+00:00" />
<meta itemprop="wordCount" content="1177">



<meta itemprop="keywords" content="" />


  
  <link media="screen" rel="stylesheet" href='https://surveyjds.onrender.com/css/common.css'>
  <link media="screen" rel="stylesheet" href='https://surveyjds.onrender.com/css/content.css'>

  
  
  <title>Unleash Natural Language Processsing on Survey Comments - Savvy Surveys for Lawyers</title>
  

  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Unleash Natural Language Processsing on Survey Comments"/>
<meta name="twitter:description" content="Law firms and law departments periodically conduct surveys of their members or clients to learn about a topic, e.g., engagement, work-from-home policies, client satisfaction, or use of AI software. Questions on the survey may invite respondents to write as much as they want for an answer. For example, â€œHow have you encountered and dealt with supply-chain obstructions?â€ I will call them â€œtext questions.â€
The old-fashioned way to identify and classify ideas from free-text responses to text questions has been to read and code them by hand."/>


  
<link rel="stylesheet" href='https://surveyjds.onrender.com/css/single.css'>

</head>

<body>
  <div id="wrapper">
    <script data-goatcounter="https://savvysurveys.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
<head>  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KF8MEL9SCH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-KF8MEL9SCH');
  </script></head>
<header id="header">
  <h1>
    <a href="https://surveyjds.onrender.com">Savvy Surveys for Lawyers</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="link" href="/about/">About</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="link" href="/services/">Services</a>
    </span>
    
  </nav>
</header>

    
<main id="main" class="post">
  
  
  <h1>Unleash Natural Language Processsing on Survey Comments</h1>
  
  
  <article class="content">
    
    


<p>Law firms and law departments periodically conduct surveys of their members or clients to learn about a topic, e.g., engagement, work-from-home policies, client satisfaction, or use of AI software. Questions on the survey may invite respondents to write as much as they want for an answer. For example, â€œHow have you encountered and dealt with supply-chain obstructions?â€ I will call them â€œtext questions.â€</p>
<p>The old-fashioned way to identify and classify ideas from free-text responses to text questions has been to read and code them by hand. This is why you benefit from Natural Language Processing (NLP) tools. Defensible and reproducible coding of text is hard to do well because the coder may be biased or inattentive, the codes keep evolving, concepts are entangled, the amount to process is large, or it is monotonous, sucks up time and has no definitive stopping point. In short, coding text by hand is rife with challenges.</p>
<p>Today, the technology-savvy firm or department will complement manual coding of text comments with analyzing them through NLP algorithms (also known as â€œtext analysisâ€ or â€œtext miningâ€). Of course, questions seeking a written response should be clear and neutral in tone; they should also be read by someone to purge them of anything that would identify the writer, because some or all of the responses might be included in a report.</p>
<p>In this first part of a series of articles, we will describe the preparatory steps for any NLP project. Its focus is the steps to transform your tousled, bed-head comments into coiffed statistical form. Part II will explain four common NLP analyses that your firm or department can then carry out:</p>
<ol style="list-style-type: decimal">
<li>A word cloud that displays the most-commonly used significant words;</li>
<li>A sentiment classification of the comments;</li>
<li>A network graph of frequently paired words in the comments; and</li>
<li>Clustering the comments by similarity of words used.</li>
</ol>
<p>Part III will cover ways that NLP software can tease out topics in the comments, even across questions, that coders might miss or mishandle: so-called latent topic models.</p>
<p>Survey analysts of law firms and law departments can turn to the free, open-source R or Python programming languages to take advantage of NLP methods (other tools include MonkeyLearn and Power BI). Both programming languages start by reading the text in from a spreadsheet that has stored each respondentsâ€™ comments on a row with the question in one column and whatever was written in another column.</p>
<p>At the starting point for unleashing NLP algorithms is <strong>tokenization</strong> (I have bold-faced technical terms), which refers to the way you define and identify the unit of analysis. For making sense of survey comments, our tokens will be words. Once all comments are tokenized, the software deletes typical non-significant words (such as â€œtheâ€, â€œisâ€, â€œofâ€, called <strong>stop words</strong> as they add no informational value). You combine hyphenated words such as â€œwrite-offsâ€ and â€œpost-decisionâ€ because otherwise they would be treated as separate words after the hyphen is removed. Your software also removes numbers, punctuation and special characters (like /, @ and $) while it converts all words to lower case (a computer regards â€œInvoiceâ€ as a different token than â€œinvoiceâ€). This leaves a cleaned <strong>corpus</strong> â€“ NLP jargon for a group of documents, as each free-text question here would be considered a document and each word a term.</p>
<p>Next, the analyst typically has the software complete several of the following preparatory steps:</p>
<p>â€¢ Remove additional words that were used so often that they convey little information (domain-specific stop words, such as â€œlawyerâ€ or â€œlaw departmentâ€).</p>
<p>â€¢ Correct misspelled words or non-ASCII characters.</p>
<p>â€¢ Convert variants of a word into one form, so that â€œorigination,â€ â€œoriginates,â€ â€œoriginatedâ€, and â€œoriginatorâ€ all became â€œoriginatâ€ (called <strong>stemming</strong>).</p>
<p>â€¢ Standardize forms of a verb into one form, called <strong>lemmatization</strong>, so that â€œrunningâ€, â€œran,â€ and â€œrunsâ€ become â€œrunâ€ and â€œinvoicesâ€ becomes â€œinvoice.â€</p>
<p>â€¢ Treat compound words as one word, such as â€œoutside counselâ€ changes to â€œoutsideCounselâ€ or â€œgeneral counselâ€ becomes â€œgeneralCounsel.â€</p>
<p>â€¢ Expand contractions and slang into proper words (â€œdoesnâ€™tâ€ to â€œdoes notâ€ and â€œBSâ€ to â€œnonsense.â€</p>
<p>These text standardizing and scrubbing actions might trigger another cull of stop words. In fact, the whole process sounds more cumbersome than it is. Once your text question entries can be read into your <strong>programming script</strong> â€“ the code that does the heavy lifting â€“ the text cleaning described above takes the software seconds to complete, although the analyst will take more iterative steps as he or she scrutinizes the results and makes revisions.</p>
<p>What happens to the words? It is common in NLP analyses to rely on a <strong>bag-of-words (BoW)</strong> breakdown of the corpus, which means the software counts how many times each word appears in each comment but disregards the grammatical role of the word (its part of speech as in subject, object, verb) as well as the words order in the comment. Basic NLP preserves no context nor semantics.</p>
<p>At this point, the software creates a virtual spreadsheet (in the computerâ€™s memory) of one row for each entry to a text question, and a column for each different word in all the entries. In a large survey, say with 100 partners responding, you can have several thousand unique words in the text comments to a question. If so, the softwareâ€™s object would have 100 rows by several thousand columns.</p>
<p>This format is called a <strong>document-term matrix (DTM) </strong>. The cells of DTM contain the number of times each word appears in that comment. For survey text-mining, the â€œdocumentsâ€ are comments to a text question, and the terms are scrubbed â€œwords.â€ A <strong>matrix</strong> is a rows-by-columns collection of numbers; hence, a DTM is a document-term matrix. Since many of the cells are empty â€“ many of the words only once in the set of comments to a particular question â€“ it is likely to be a so-called <strong>sparse matrix</strong>.</p>
<p>More sophisticated NLP techniques incorporate the order of words, parts of speech and external data, but BoW document-term matrices support ample analytical power, since a raft of statistical and mathematical calculations can come from them. Also, we should note one variation of the DTM described above.</p>
<p><strong>Term Frequency-Inverse Document Frequency (TF-IDF) </strong> is a matrix that differs from simply counting words to find the most popular words in the document. It is used in more advanced NLP tasks. TF-IDF weights the count of words (the â€œterm frequencyâ€) by how often that word appears across all comments (the â€œinverse document frequencyâ€). If a word shows up in most text question response, the term frequency is large and the document frequency is large, so the inverse document frequency (one divided by the document frequency) is small â€“ which gives that word a reduced value. If a term is popular in one document but not others, the document frequency is small and so the relative document frequency is large, giving a large value in the rare document in which it appears. A TF-IDF matrix spot and â€œupvotesâ€ words that are rare across documents or uncommonly frequent within documents.</p>
<p>Now, you are ready to mine text with NLP!</p>

    
  </article>
  <div class="paginator">
    
    <a class="link" href="https://surveyjds.onrender.com/post/2022-05-30-avoid-bias-in-the-order-of-items-for-multiple-choice-questions/survorderitems/">â† prev</a>
    
    
    <a class="link" href="https://surveyjds.onrender.com/post/2022-06-01-construct-index-variables-but-carefully/survindexvars/">next â†’</a>
    
  </div>
  <div class="comment">
    
    
    
    
    
    
  </div>
  
</main>

    <footer id="footer">
  <div>
    <span>Â© 2022</span> - <span>2023</span>
  </div>

  <div>
    <span>Powered by </span>
    <a class="link" href="https://gohugo.io/">Hugo</a>
    <span> ğŸ¦ Theme </span>
    <a class="link" href="https://github.com/queensferryme/hugo-theme-texify">TeXify</a>
  </div>

  <div class="footnote">
    <span></span>
  </div>
</footer>

  </div>

  
  

  
  

  
  

</body>

</html>
