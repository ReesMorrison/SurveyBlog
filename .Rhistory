kable_classic_2() %>%
kable_styling(position = "center", full_width = FALSE, latex_options = "hold_position") %>%
row_spec(0, bold = TRUE, align = "c")
ggplot(gcComp, aes(x = GC, y = DGC)) +
geom_point(pch = 20, size = 5) +
labs(x = "GC Compensation", y = "DGC Compensation", title = "Comparing Compensation of GC to DGC") +
scale_y_continuous(breaks = seq(0, 500000, 50000), labels = scales::dollar_format()) +
scale_x_continuous(breaks = seq(0, 600000, 50000), labels = scales::dollar_format())
knitr::kable(gcComp, booktabs = TRUE) %>%
kable_classic_2() %>%
kable_styling(position = "center", full_width = FALSE, latex_options = "hold_position") %>%
row_spec(0, bold = TRUE, align = "c")
blogdown:::new_post_addin()
blogdown:::new_post_addin()
stop_server()
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)  # frequently used packages that follow a similar coding approach
library(blogdown)
library(knitr)
library(funModeling) # to compare vectors against each other, such as URLs of posts
library(ggthemes) # to include the theme_tufte them in plots
library(lubridate) # to deal with date data, such as the date a post is published
library(ggrepel) # to spread points or text so that they do not overlap on a plot
library(readxl) # to read in the underlying Excel data
library(tidytext) # text-mining functions that help analyse the content of posts
library(writexl)
library(kableExtra)
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
figPath <- "C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/"
![ ](paste0(figpath, "RStudio Screenshot Scripts Post.png"))
![RStudio](paste0(figpath, "RStudio Screenshot Scripts Post.png"))
![RStudio]("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudio Screenshot Scripts Post.png")
!["RStudio"]("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudio Screenshot Scripts Post.png")
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudio Screenshot Scripts Post.png")
blogdown:::new_post_addin()
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioScriptsPost.png")
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioIDEScripts.png")
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
# ![RStudio](paste0(figpath, "RStudio Screenshot Scripts Post.png"))
# !["RStudio"]("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudio Screenshot Scripts Post.png")
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioIDEScripts.png")
C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioIDEScripts.png
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioIDEScripts.png")
# ![RStudio](paste0(figpath, "RStudio Screenshot Scripts Post.png"))
knitr::include_graphics("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/SurveyBlog/static/media/RStudioIDEScripts.png")
warnings()
0.98/10
0.98/sqrt(800)
0.98/sqrt(200)
0.98/sqrt(50)
1/25
1/.25
1/.0025
0.98/sqrt(100)
0.98/sqrt(200)
.07*600000
642-558
84/120
stop_server()
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
stop_server()
help("mad")
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)  # frequently used packages that follow a similar coding approach
library(blogdown)
library(knitr)
library(funModeling) # to compare vectors against each other, such as URLs of posts
library(ggthemes) # to include the theme_tufte them in plots
library(lubridate) # to deal with date data, such as the date a post is published
library(ggrepel) # to spread points or text so that they do not overlap on a plot
library(readxl) # to read in the underlying Excel data
library(tidytext) # text-mining functions that help analyse the content of posts
library(writexl)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)  # frequently used packages that follow a similar coding approach
library(blogdown)
library(knitr)
library(funModeling) # to compare vectors against each other, such as URLs of posts
library(ggthemes) # to include the theme_tufte them in plots
library(lubridate) # to deal with date data, such as the date a post is published
library(ggrepel) # to spread points or text so that they do not overlap on a plot
library(readxl) # to read in the underlying Excel data
library(tidytext) # text-mining functions that help analyse the content of posts
library(writexl)
library(kableExtra)
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
stop_server()
blogdown:::new_post_addin()
serve_site()
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)  # frequently used packages that follow a similar coding approach
library(blogdown)
library(knitr)
library(funModeling) # to compare vectors against each other, such as URLs of posts
library(ggthemes) # to include the theme_tufte them in plots
library(lubridate) # to deal with date data, such as the date a post is published
library(ggrepel) # to spread points or text so that they do not overlap on a plot
library(readxl) # to read in the underlying Excel data
library(tidytext) # text-mining functions that help analyse the content of posts
library(writexl)
library(kableExtra)
serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
stop_server()
serve_site()
blogdown:::new_post_addin()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(ggthemes)
library(reticulate)
library(tidytext)
library(pluralize)  # to lemmatize
library(textstem)  # to lemmatize
input <- read_lines("C:/Users/Rees Morrison/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/SavSurveyGuide.Rmd")
input <- read_lines("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/SavSurveyGuide.Rmd")
# combine all the text, with a space between each term
text <- paste0(input, collapse = " ")
terms <- data.frame(Terms = str_extract_all(text, pattern = "\\*\\*.+?\\*\\*", simplify = FALSE))
colnames(terms) <- "Terms"
terms$Terms <- str_remove_all(string = terms$Terms, pattern = "\\*\\*")
terms$Terms <- str_to_lower(terms$Terms)
terms$Terms <- str_replace_all(terms$Terms, "analytic report", replacement = "report")
terms$Terms <- str_replace_all(terms$Terms, "closed", replacement = "closing date")
terms$Terms <- str_replace_all(terms$Terms, "conditional.*", replacement = "conditional logic question")
terms$Terms <- str_replace_all(terms$Terms, "cross-tabulation", replacement = "cross tabulation")
terms$Terms <- str_replace_all(terms$Terms, "demographics", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "demographic information", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "drop-out", replacement = "drop out")
terms$Terms <- str_replace_all(terms$Terms, "duplicate.*", replacement = "duplicate response")
terms$Terms <- str_replace_all(terms$Terms, "email manager", replacement = "bulk-mailing software")
terms$Terms <- str_replace_all(terms$Terms, "frequently asked question", replacement = "FAQs")
terms$Terms <- str_replace_all(terms$Terms, "host software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "invitational email", replacement = "invitation email")
terms$Terms <- str_replace_all(terms$Terms, "lemma.*", replacement = "lemmatize")
terms$Terms <- str_replace_all(terms$Terms, "logic questions", replacement = "logic  question")
terms$Terms <- str_replace_all(terms$Terms, "methodology section", replacement = "methodology")
terms$Terms <- str_replace_all(terms$Terms, "multiple choice questions", replacement = "multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "multiple-choice questions", replacement =
"multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "navigation", replacement = "navigate")
terms$Terms <- str_replace_all(terms$Terms, "normalizing step", replacement = "normalize data")
terms$Terms <- str_replace_all(terms$Terms, "partial responses", replacement = "partial response")
terms$Terms <- str_replace_all(terms$Terms, "pretest", replacement = "pre-test")
terms$Terms <- str_replace_all(terms$Terms, "pre-tested", replacement = "pre-testing")
terms$Terms <- str_replace_all(terms$Terms, "rankings", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "ranking questions", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "regex", replacement = "regular expression")
terms$Terms <- str_replace_all(terms$Terms, "representativeness", replacement = "representative")
terms$Terms <- str_replace_all(terms$Terms, "required fields", replacement = "required question")
terms$Terms <- str_replace_all(terms$Terms, "scripting language", replacement = "scripting software")
terms$Terms <- str_replace_all(terms$Terms, "survey software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "survey analyst", replacement = "analyst")
terms$Terms <- str_replace_all(terms$Terms, "survey sponsor", replacement = "sponsor")
terms$Terms <- str_replace_all(terms$Terms, "text boxes", replacement = "text box")
terms$Terms <- str_replace_all(terms$Terms, "third party", replacement = "third party assistance")
terms$SingularTerms <- pluralize::singularize(terms$Terms)
termsCount <- terms %>% group_by(SingularTerms) %>%
summarize(Count = n()) %>% arrange(SingularTerms)
colnames(termsCount)[1] <- "Terms"
View(termsCount)
input <- read_lines("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/SavSurveyGuide.Rmd")
# combine all the text, with a space between each term
text <- paste0(input, collapse = " ")
# extract the bolded ** terms
terms <- data.frame(Terms = str_extract_all(text, pattern = "\\*\\*.+?\\*\\*", simplify = FALSE))
colnames(terms) <- "Terms"
terms$Terms <- str_remove_all(string = terms$Terms, pattern = "\\*\\*")
terms$Terms <- str_to_lower(terms$Terms)
# exceptions to lower case would be MECE, Other
# fix variations; could do in SavSurveyGuide.Rmd; figure out regex for "not followed by ..." so I can fix disqualified to disqualified response without messing up existing "disqualified response"
terms$Terms <- str_replace_all(terms$Terms, "analytic report", replacement = "report")
terms$Terms <- str_replace_all(terms$Terms, "closed", replacement = "closing date")
terms$Terms <- str_replace_all(terms$Terms, "conditional.*", replacement = "conditional logic question")
terms$Terms <- str_replace_all(terms$Terms, "cross-tabulation", replacement = "cross tabulation")
terms$Terms <- str_replace_all(terms$Terms, "demographics", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "demographic information", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "drop-out", replacement = "drop out")
terms$Terms <- str_replace_all(terms$Terms, "duplicate.*", replacement = "duplicate response")
terms$Terms <- str_replace_all(terms$Terms, "email manager", replacement = "bulk-mailing software")
terms$Terms <- str_replace_all(terms$Terms, "frequently asked question", replacement = "FAQs")
terms$Terms <- str_replace_all(terms$Terms, "host software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "invitational email", replacement = "invitation email")
terms$Terms <- str_replace_all(terms$Terms, "lemma.*", replacement = "lemmatize")
terms$Terms <- str_replace_all(terms$Terms, "logic questions", replacement = "logic  question")
terms$Terms <- str_replace_all(terms$Terms, "methodology section", replacement = "methodology")
terms$Terms <- str_replace_all(terms$Terms, "multiple choice questions", replacement = "multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "multiple-choice questions", replacement =
"multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "navigation", replacement = "navigate")
terms$Terms <- str_replace_all(terms$Terms, "normalizing step", replacement = "normalize data")
terms$Terms <- str_replace_all(terms$Terms, "partial responses", replacement = "partial response")
terms$Terms <- str_replace_all(terms$Terms, "pretest", replacement = "pre-test")
terms$Terms <- str_replace_all(terms$Terms, "pre-tested", replacement = "pre-testing")
terms$Terms <- str_replace_all(terms$Terms, "rankings", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "ranking questions", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "regex", replacement = "regular expression")
terms$Terms <- str_replace_all(terms$Terms, "representativeness", replacement = "representative")
terms$Terms <- str_replace_all(terms$Terms, "required fields", replacement = "required question")
terms$Terms <- str_replace_all(terms$Terms, "scripting language", replacement = "scripting software")
terms$Terms <- str_replace_all(terms$Terms, "survey software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "survey analyst", replacement = "analyst")
terms$Terms <- str_replace_all(terms$Terms, "survey sponsor", replacement = "sponsor")
terms$Terms <- str_replace_all(terms$Terms, "text boxes", replacement = "text box")
terms$Terms <- str_replace_all(terms$Terms, "third party", replacement = "third party assistance")
# make the KSTs singular
# https://stackoverflow.com/questions/34938023/r-text-mining-dealing-with-plurals
terms$SingularTerms <- pluralize::singularize(terms$Terms)
termsCount <- terms %>% group_by(SingularTerms) %>%
summarize(Count = n()) %>% arrange(SingularTerms)
colnames(termsCount)[1] <- "Terms"   # 312 obs on 1/19/23 with 70 posts in SavSurveyGuide.Rmd
View(termsCount)
writexl::write_xlsx(x = termsCount, path = "C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/termsCount.xlsx")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(ggthemes)
library(reticulate)
library(tidytext)
library(pluralize)  # to lemmatize
library(textstem)  # to lemmatize
input <- read_lines("C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/SavSurveyGuide.Rmd")
# combine all the text, with a space between each term
text <- paste0(input, collapse = " ")
# extract the bolded ** terms
terms <- data.frame(Terms = str_extract_all(text, pattern = "\\*\\*.+?\\*\\*", simplify = FALSE))
colnames(terms) <- "Terms"
terms$Terms <- str_remove_all(string = terms$Terms, pattern = "\\*\\*")
terms$Terms <- str_to_lower(terms$Terms)
# exceptions to lower case would be MECE, Other
# fix variations; could do in SavSurveyGuide.Rmd; figure out regex for "not followed by ..." so I can fix disqualified to disqualified response without messing up existing "disqualified response"
terms$Terms <- str_replace_all(terms$Terms, "analytic report", replacement = "report")
terms$Terms <- str_replace_all(terms$Terms, "closed", replacement = "closing date")
terms$Terms <- str_replace_all(terms$Terms, "conditional.*", replacement = "conditional logic question")
terms$Terms <- str_replace_all(terms$Terms, "cross-tabulation", replacement = "cross tabulation")
terms$Terms <- str_replace_all(terms$Terms, "demographics", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "demographic information", replacement = "demographic question")
terms$Terms <- str_replace_all(terms$Terms, "drop-out", replacement = "drop out")
terms$Terms <- str_replace_all(terms$Terms, "duplicate.*", replacement = "duplicate response")
terms$Terms <- str_replace_all(terms$Terms, "email manager", replacement = "bulk-mailing software")
terms$Terms <- str_replace_all(terms$Terms, "frequently asked question", replacement = "FAQs")
terms$Terms <- str_replace_all(terms$Terms, "host software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "invitational email", replacement = "invitation email")
terms$Terms <- str_replace_all(terms$Terms, "lemma.*", replacement = "lemmatize")
terms$Terms <- str_replace_all(terms$Terms, "logic questions", replacement = "logic  question")
terms$Terms <- str_replace_all(terms$Terms, "methodology section", replacement = "methodology")
terms$Terms <- str_replace_all(terms$Terms, "multiple choice questions", replacement = "multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "multiple-choice questions", replacement =
"multiple-choice question")
terms$Terms <- str_replace_all(terms$Terms, "navigation", replacement = "navigate")
terms$Terms <- str_replace_all(terms$Terms, "normalizing step", replacement = "normalize data")
terms$Terms <- str_replace_all(terms$Terms, "partial responses", replacement = "partial response")
terms$Terms <- str_replace_all(terms$Terms, "pretest", replacement = "pre-test")
terms$Terms <- str_replace_all(terms$Terms, "pre-tested", replacement = "pre-testing")
terms$Terms <- str_replace_all(terms$Terms, "rankings", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "ranking questions", replacement = "ranking question")
terms$Terms <- str_replace_all(terms$Terms, "regex", replacement = "regular expression")
terms$Terms <- str_replace_all(terms$Terms, "representativeness", replacement = "representative")
terms$Terms <- str_replace_all(terms$Terms, "required fields", replacement = "required question")
terms$Terms <- str_replace_all(terms$Terms, "scripting language", replacement = "scripting software")
terms$Terms <- str_replace_all(terms$Terms, "survey software", replacement = "hosting software")
terms$Terms <- str_replace_all(terms$Terms, "survey analyst", replacement = "analyst")
terms$Terms <- str_replace_all(terms$Terms, "survey sponsor", replacement = "sponsor")
terms$Terms <- str_replace_all(terms$Terms, "text boxes", replacement = "text box")
terms$Terms <- str_replace_all(terms$Terms, "third party", replacement = "third party assistance")
# make the KSTs singular
# https://stackoverflow.com/questions/34938023/r-text-mining-dealing-with-plurals
terms$SingularTerms <- pluralize::singularize(terms$Terms)
termsCount <- terms %>% group_by(SingularTerms) %>%
summarize(Count = n()) %>% arrange(SingularTerms)
colnames(termsCount)[1] <- "Terms"   # 294 obs on 1/19/23 with 70 posts in SavSurveyGuide.Rmd
writexl::write_xlsx(x = termsCount, path = "C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SurveyBook/termsCount.xlsx")
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(bookdown)
library(tidytext)
library(kableExtra)
library(cowplot)
# from https://appsilon.com/imputation-in-r/
imp <- readxl::read_xlsx("C:/Users/rees/Documents/R/Projects/CLIENTS/LFExecDirs/combo121.xlsx")
#keep only numerics and a few of them
imp <- imp[    , c("YearsRole", "Reports", "Lawyers", "Base", "Bonus", "Total")]  # 225 obs
library(titanic)
library(missForest)
install.packages("titanic")
library(titanic)
titanic_train$Age
library(mice)
md.pattern(imp, rotate.names = TRUE)
value_imputed <- data.frame(
original = imp$Base,
imputed_zero = replace(imp$Base, is.na(imp$Base), 8),
imputed_mean = replace(imp$Base, is.na(imp$Base), mean(imp$Base, na.rm = TRUE)),
imputed_median = replace(imp$Base, is.na(imp$Base), median(imp$Base, na.rm = TRUE))
)
h1 <- ggplot(value_imputed, aes(x = original)) +
geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h2 <- ggplot(value_imputed, aes(x = imputed_zero)) +
geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
ggtitle("Constant-imputed distribution") +
theme_classic()
h3 <- ggplot(value_imputed, aes(x = imputed_mean)) +
geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
ggtitle("Mean-imputed distribution") +
theme_classic()
h4 <- ggplot(value_imputed, aes(x = imputed_median)) +
geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
ggtitle("Median-imputed distribution") +
theme_classic()
plot_grid(h1, h2, h3, h4, nrow = 2, ncol = 2)
missForest_imputed <- data.frame(
original = imp$Base,
imputed_missForest = missForest(imp)$ximp$Base
)
mice_imputed
mice_imputed <- data.frame(
original = imp$Base,
imputed_pmm = complete(mice(imp, method = "pmm"))$Base,
imputed_cart = complete(mice(imp, method = "cart"))$Base,
imputed_lasso = complete(mice(imp, method = "lasso.norm"))$Base
)
mice_imputed
View(mice_imputed)
imp <- readxl::read_xlsx("C:/Users/rees/Documents/R/Projects/CLIENTS/LFExecDirs/combo121.xlsx")
#keep only numerics and a few of them
imp <- imp[    , c("YearsRole", "Reports", "Lawyers", "Base", "Bonus", "Total")]  # 225 obs
View(imp)
imp$Base[61] <- NA
View(imp)
imp$Base[124] <- 114000
imp$Bonus[124] <- 12000
imp$Total[124] <- 126000
View(imp)
value_imputed <- data.frame(
original = imp$Base,
imputed_zero = replace(imp$Base, is.na(imp$Base), 125000),  # picked a plausible value
imputed_mean = replace(imp$Base, is.na(imp$Base), mean(imp$Base, na.rm = TRUE)),
imputed_median = replace(imp$Base, is.na(imp$Base), median(imp$Base, na.rm = TRUE))
)
h1 <- ggplot(value_imputed, aes(x = original)) +
geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h2 <- ggplot(value_imputed, aes(x = imputed_zero)) +
geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
ggtitle("Constant-imputed distribution") +
theme_classic()
h3 <- ggplot(value_imputed, aes(x = imputed_mean)) +
geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
ggtitle("Mean-imputed distribution") +
theme_classic()
h4 <- ggplot(value_imputed, aes(x = imputed_median)) +
geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
ggtitle("Median-imputed distribution") +
theme_classic()
plot_grid(h1, h2, h3, h4, nrow = 2, ncol = 2)
mice_imputed <- data.frame(
original = imp$Base,
imputed_pmm = complete(mice(imp, method = "pmm"))$Base,
imputed_cart = complete(mice(imp, method = "cart"))$Base,
imputed_lasso = complete(mice(imp, method = "lasso.norm"))$Base
)
h1 <- ggplot(value_imputed, aes(x = original)) +
geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h2 <- ggplot(mice_imputed, aes(x = imputed_pmm)) +
geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h3 <- ggplot(mice_imputed, aes(x = imputed_cart)) +
geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
ggtitle("Constant-imputed distribution") +
theme_classic()
h4 <- ggplot(mice_imputed, aes(x = imputed_lasso)) +
geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
ggtitle("Mean-imputed distribution") +
theme_classic()
plot_grid(h1, h2, h3, h4, nrow = 2, ncol = 2)
h1 <- ggplot(value_imputed, aes(x = original)) +
geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h2 <- ggplot(mice_imputed, aes(x = imputed_pmm)) +
geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
ggtitle("Imputed by PMM") +
theme_classic()
h3 <- ggplot(mice_imputed, aes(x = imputed_cart)) +
geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
ggtitle("Imputed by CART") +
theme_classic()
h4 <- ggplot(mice_imputed, aes(x = imputed_lasso)) +
geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
ggtitle("Imputed by Lasso") +
theme_classic()
plot_grid(h1, h2, h3, h4, nrow = 2, ncol = 2)
library(missForest)
missForest_imputed <- data.frame(
original = imp$Base,
imputed_missForest = missForest(imp)$ximp$Base
)
h1 <- ggplot(mice_imputed, aes(x = original)) +
geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
ggtitle("Original distribution") +
theme_classic()
h2 <- ggplot(mice_imputed, aes(x = imputed_pmm)) +
geom_histogram(fill = "#ad8415", color = "#000000", position = "identity") +
ggtitle("Imputed by PMM") +
theme_classic()
h3 <- ggplot(mice_imputed, aes(x = imputed_cart)) +
geom_histogram(fill = "#15ad4f", color = "#000000", position = "identity") +
ggtitle("Imputed by CART") +
theme_classic()
h4 <- ggplot(mice_imputed, aes(x = imputed_lasso)) +
geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
ggtitle("Imputed by Lasso") +
theme_classic()
plot_grid(h1, h2, h3, h4, nrow = 2, ncol = 2)
View(mice_imputed)
ImputedValues <- subset(mice_imputed, is.na(original))
View(ImputedValues)
titanic_numeric <- titanic_train %>%
select(Survived, Pclass, SibSp, Parch, Age)
View(titanic_numeric)
md.pattern(titanic_numeric)
imp$Bonus[142] <- 10000
impNoNAs <- imp[  , 1:4]
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$ximp$Base
)
View(impNoNAs)
impNoNAs <- impNoNAs[-c(116, 134), ] # missing values in Reports
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$ximp$Base
)
impNoNAs$YearsRole <- as.numeric(impNoNAs$YearsRole)
impNoNAs$YearsRole <- as.numeric(impNoNAs$YearsRole)
impNoNAs$Reports <- as.numeric(impNoNAs$Reports)
impNoNAs$Lawyers <- as.numeric(impNoNAs$Lawyers)
summary(impNoNAs$YearsRole)
summary(impNoNAs$Reports)
View(impNoNAs)
impNoNAs <- impNoNAs[-18, ] # missing values in Reports
impNoNAs$Reports <- as.numeric(impNoNAs$Reports)
summary(impNoNAs$Reports)
summary(impNoNAs$Lawyers)
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$ximp$Base
)
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$Base
)
View(impNoNAs)
missForest_imputed <- data.frame(
original = titanic_numeric$Age,
imputed_missForest = missForest(titanic_numeric)$ximp$Age
)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(bookdown)
library(tidytext)
library(kableExtra)
library(cowplot)
# from https://appsilon.com/imputation-in-r/
imp <- readxl::read_xlsx("C:/Users/rees/Documents/R/Projects/CLIENTS/LFExecDirs/combo121.xlsx")
#keep only numerics and a few of them
imp <- imp[    , c("YearsRole", "Reports", "Lawyers", "Base", "Bonus", "Total")]  # 225 obs
imp$Base[61] <- NA
imp$Base[124] <- 114000
imp$Bonus[124] <- 12000
imp$Total[124] <- 126000
imp$Bonus[142] <- 10000
library(missForest)
impNoNAs <- imp[  , 1:4] # removed Bonus and Total because they have NAs
impNoNAs <- impNoNAs[-c(116, 134), ] # missing values in Reports
impNoNAs <- impNoNAs[-18, ] # missing value in Reports
impNoNAs$YearsRole <- as.numeric(impNoNAs$YearsRole)
impNoNAs$Reports <- as.numeric(impNoNAs$Reports)
impNoNAs$Lawyers <- as.numeric(impNoNAs$Lawyers)
impNoNAs$Base <- as.numeric(impNoNAs$Base)
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$ximp$Base
)
missForest_imputed <- data.frame(
original = impNoNAs$Base,
imputed_missForest = missForest(impNoNAs)$ximp$Base
)
writexl::write_xlsx(impNoNAs, "C:/Users/rees/Documents/R/Projects/LAWYER Hornbooks/5Surveys/SavSurvBlog/imputationdf.xlsx")
